{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3f9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, log_loss, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b3b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the full dataframe from Assignment 5\n",
    "merged_df = pd.read_csv(\"merged_final.csv\")\n",
    "\n",
    "# adding stock value as a column\n",
    "merged_df['value'] = merged_df['PRC'] * merged_df['VOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e59b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_month = pd.read_sas(\"ff_factors_monthly.sas7bdat\")\n",
    "\n",
    "rf_month['dateff'] = pd.to_datetime(rf_month['dateff'])\n",
    "#rf_month = rf_month[rf_month['dateff']]\n",
    "rf_month = rf_month[rf_month['dateff'].dt.year >= 1980]\n",
    "rf_month = rf_month[['dateff', 'RF']]\n",
    "\n",
    "def month_format(month):\n",
    "    if len(month) == 1:\n",
    "        month = str(0) + month\n",
    "        return month\n",
    "    else:\n",
    "        return month\n",
    "\n",
    "rf_month['year'] = rf_month['dateff'].apply(lambda x: str(x.year))\n",
    "rf_month['month'] = rf_month['dateff'].apply(lambda x: str(x.month))\n",
    "rf_month['month'] = rf_month['month'].apply(month_format)\n",
    "rf_month['yyyymm'] = rf_month['year'] + rf_month['month']\n",
    "rf_month['yyyymm'] = rf_month['yyyymm'].apply(lambda x: float(x))\n",
    "\n",
    "rf_month = rf_month[['RF', 'yyyymm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40906eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding risk free rate to merged_df\n",
    "merged_df = merged_df.merge(rf_month, on = ['yyyymm'])\n",
    "\n",
    "# setting index to permno-yyyymm\n",
    "merged_df['permno-yyyymm'] = merged_df['permno'].apply(lambda x: str(x)) + merged_df['yyyymm'].apply(lambda x: str(x)[:-2])\n",
    "merged_df['permno-yyyymm'] = merged_df['permno-yyyymm'].apply(lambda x: int(x))\n",
    "merged_df.set_index(merged_df['permno-yyyymm'], inplace = True)\n",
    "\n",
    "# dropping the permno-yyyymm column\n",
    "merged_df.drop(['permno-yyyymm'], axis= 1, inplace= True)\n",
    "#merged_df.drop(['Unnamed: 0'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b76bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a 60/20/20 split\n",
    "train, validate, test = \\\n",
    "                        np.split(merged_df.sample(frac=1, random_state=42), \n",
    "                        [int(.6*len(merged_df)), int(.8*len(merged_df))])\n",
    "\n",
    "factors = list(train.columns[9:41])\n",
    "\n",
    "x_train = train[factors]\n",
    "y_train = train['RET']\n",
    "\n",
    "x_validate = validate[factors]\n",
    "y_validate = validate['RET']\n",
    "\n",
    "x_test = test[factors]\n",
    "y_test = test['RET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff03d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation function\n",
    "def validate_model(model_type, param_grid, x_train, y_train, x_validate, y_validate):\n",
    "    # Special case for LinearRegression because it doesn't have hyperparameters to tune\n",
    "    if model_type == LinearRegression:\n",
    "        model = LinearRegression()\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_validate)\n",
    "        r2 = r2_score(y_validate, pred)\n",
    "        \n",
    "        return r2\n",
    "    else: # The other cases\n",
    "        \n",
    "        # Establishses the ParameterGrid\n",
    "        model_param_grid = ParameterGrid(param_grid)\n",
    "        \n",
    "        # Initialize values\n",
    "        best_MAE = 0\n",
    "        best_r2 = 1\n",
    "        best_config = None\n",
    "        # Iterate through the parameter grid, fit models to the hyperparameters\n",
    "        # and check for MAE and R2 values\n",
    "        \n",
    "        # each param_config in that validation function would represent 1 combination of the possible parameters.\n",
    "        # for example in Lab 6, when I'm validating for the elastic net regression, I have \n",
    "        # 2 possible hyperparameters: alpha and l1_ratio. \n",
    "        #alpha can take on values 0.0001, 0.0005, etc, and l1_ratio can take on values 0, 1, 0.01. \n",
    "        #So each param_config in the for loop in validate_model would go over 1 possible \n",
    "        #combination of the hyperparameter and keep the one that gives us the best MAE/R2\n",
    "        for param_config in model_param_grid:\n",
    "            curr_config_MAEs = []\n",
    "            model = model_type(**param_config)\n",
    "            model.fit(x_train, y_train)\n",
    "            pred = model.predict(x_validate)\n",
    "            MAE = mean_squared_error(y_validate,pred)\n",
    "            r2 = r2_score(y_validate, pred)\n",
    "            curr_config_MAEs.append(MAE)\n",
    "            if best_MAE == 0 or (MAE < best_MAE):\n",
    "                best_MAE = MAE\n",
    "                best_config = param_config\n",
    "            if best_r2 == 1 or (r2 > best_r2):\n",
    "                best_r2 = r2\n",
    "        return best_config, best_MAE, best_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba52546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "def pred(model_type, x_train, y_train, x_test, y_test):\n",
    "    # Fit model and predict \n",
    "    model = model_type.fit(x_train, y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # Format prediction as DataFrame\n",
    "    pred_df = pd.DataFrame(pred, columns = ['RET_pred'])\n",
    "    pred_df.set_index(x_test.index, inplace = True)\n",
    "    \n",
    "    r2 = r2_score(y_test, pred)\n",
    "    return pred_df, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5426597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_extract(index):\n",
    "    return int(str(index)[5:])\n",
    "# vectorizes the function\n",
    "vyear_extract = np.vectorize(year_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1477ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the portfolio and calculate different performance metrics\n",
    "def portfolio_build(df_pred, model_name, df_realized):\n",
    "    # Get the year\n",
    "    df_pred['yyyymm'] = vyear_extract(df_pred.index.values)\n",
    "    df_pred.sort_values(by = 'yyyymm', inplace = True)\n",
    "    \n",
    "    # Initialize list of values\n",
    "    long_short_lst = []\n",
    "    value_lst = []\n",
    "    \n",
    "    # Iterate over years\n",
    "    for time in df_pred['yyyymm'].unique():\n",
    "        # Subset by year\n",
    "        df_curr = df_pred[df_pred['yyyymm'] == time]\n",
    "        # Sort the values by returns\n",
    "        df_curr = df_curr.sort_values(by = ['RET_pred'], ascending = False)\n",
    "        size = math.floor(df_curr.shape[0]/10)\n",
    "        # Get the top/bottom performing stocks\n",
    "        df_top = df_curr.head(size)\n",
    "        df_bot = df_curr.tail(size)\n",
    "        # Get the actual returns of the predicted top/bottom performers\n",
    "        df_top_realized = df_realized.loc[df_top.index]\n",
    "        df_bot_realized = df_realized.loc[df_bot.index]\n",
    "        \n",
    "    \n",
    "        # Get the mean returns of these top/bottom performers\n",
    "        mu_top = df_top_realized['RET'].mean()\n",
    "        mu_bot = df_bot_realized['RET'].mean()\n",
    "        \n",
    "     \n",
    "        # Get the mean returns by shorting the bottom and going long on the top\n",
    "        long_short = (mu_top - mu_bot)\n",
    "        \n",
    "        value = df_top['value'].sum()\n",
    "        value = value + df_bot['value'].sum()\n",
    "        \n",
    "        long_short_lst.append(long_short)\n",
    "        value_lst.append(value)\n",
    "    \n",
    "    # Get the value for the portfolio\n",
    "    ls_df = pd.DataFrame(long_short_lst, columns = ['ls_ret'], index = df_pred['yyyymm'].unique())\n",
    "    ls_df['value'] = value_lst\n",
    "    \n",
    "    # Calculating cumulative returns\n",
    "    # First we +1 to the returns \n",
    "    # Then we do the cumulative product\n",
    "    ls_df['cumulative_ret']= ls_df['ls_ret'] + 1\n",
    "    ls_df['cumulative_ret'] = ls_df['cumulative_ret'].cumprod()\n",
    "    \n",
    "    # Get mean/std/sharpe ratio for the portfolio\n",
    "    ls_df = pd.merge(ls_df, rf_month, left_index = True, right_index = True)\n",
    "    ls_df['ls_sub_rf'] = ls_df['ls_ret'] - ls_df['RF']\n",
    "    ls_sub_rf_mean = ls_df['ls_sub_rf'].mean()*12\n",
    "    ls_sub_rf_std = ls_df['ls_sub_rf'].std()*math.sqrt(12)\n",
    "    sharpe_ratio = ls_sub_rf_mean/ls_sub_rf_std*math.sqrt(12)\n",
    "    \n",
    "    print(\"The annualized excess return \"+ model_name + \" long short portfolio is: \" + str(ls_sub_rf_mean))\n",
    "    print(\"The annualized std dev of returns of \" + model_name + \" long short portfolio is: \" + str(ls_sub_rf_std))\n",
    "    print(\"The anualized Sharpe ratio of \" + model_name + \" long short portfolio is: \" + str(sharpe_ratio))\n",
    "    \n",
    "    return ls_df, ls_sub_rf_mean, ls_sub_rf_std, sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac7cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grids used for validation\n",
    "RF_para_grid_dict = {'max_depth': np.arange(1, 50, 1),\n",
    "               'n_estimators': np.arange(1, 101, 1),\n",
    "               'max_features': np.arange(1, 36, 1),\n",
    "               'n_jobs':[-1]}\n",
    "\n",
    "BGDT_para_grid_dict = {'base_estimator':[DecisionTreeRegressor(max_depth=15)], \n",
    "               'n_estimators': np.arange(1, 101, 1),\n",
    "               'max_features': np.arange(1, 36, 1),\n",
    "               'n_jobs':[-1],\n",
    "               'max_samples': np.arange(0.1, 1.1, 0.1),\n",
    "               }\n",
    "RSDT_para_grid_dict = {'base_estimator':[DecisionTreeRegressor(max_depth=15)], \n",
    "               'n_estimators': np.arange(1, 101, 1),\n",
    "               'max_features': np.arange(1, 36, 1),\n",
    "               'max_samples': [1.0],\n",
    "               'n_jobs':[-1]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20bef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample vali code for one model\n",
    "# Actual validation is ran on a random sample of 50 as training data, and random sample of 20 as validation\n",
    "# Caveat: Each model takes a long time--more than 6 hours--to run in a laptop PC\n",
    "# This part of the code is mannually terminated to save time. Results hence are not optimal\n",
    "\n",
    "# Sample vali code for one model\n",
    "# Actual validation is ran on a random sample of 50 as training data, and random sample of 20 as validation\n",
    "RF_train = merged_df.sample(n=50, random_state = 42)\n",
    "RF_validate = merged_df.sample(n=20, random_state = 100)\n",
    "\n",
    "RFx_train = train[factors]\n",
    "RFy_train = train['RET']\n",
    "\n",
    "RFx_validate = validate[factors]\n",
    "RFy_validate = validate['RET']\n",
    "\n",
    "RF_para_grid_dict = {'max_depth': np.arange(1, 50, 1),\n",
    "               'n_estimators': np.arange(1, 100, 1),\n",
    "               'max_features': np.arange(1, 32, 1),\n",
    "               'n_jobs':[-1]}\n",
    "\n",
    "#RF_para_grid = ParameterGrid(RF_para_grid_dict)\n",
    "RF_best_config, RF_best_MAE, RF_best_r2 = validate_model(RandomForestRegressor, RF_para_grid_dict, RFx_train, RFy_train, RFx_validate, RFy_validate)\n",
    "RF_para_grid_dict = {'max_depth': np.arange(1, 50, 1),\n",
    "               'n_estimators': np.arange(1, 100, 1),\n",
    "               'max_features': np.arange(1, 32, 1),\n",
    "               'n_jobs':[-1]}\n",
    "\n",
    "print('Best Config' + str(RF_best_config))\n",
    "print('Validation R2: '+ str(RF_best_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter values gotten from validation -- from a previous exercise from Nasdaq 100 firms only, instead of the full sample used\n",
    "# Make predictions \n",
    "RF_pred_df, RF_test_r2 = pred(RandomForestRegressor(max_depth= 45, max_features= 7, n_estimators= 1, n_jobs= -1),\\\n",
    "                x_train, y_train, x_test, y_test)\n",
    "BGDT_pred_df, BGDT_test_r2 = pred(BaggingRegressor(base_estimator = DecisionTreeRegressor(max_depth = 45),\\\n",
    "                              max_features = 9, max_samples= 0.4, n_estimators = 2,\\\n",
    "                              n_jobs = -1), x_train, y_train, x_test, y_test)\n",
    "RSDT_pred_df, RSDT_test_r2 = pred(BaggingRegressor(base_estimator = DecisionTreeRegressor(max_depth = 45),\\\n",
    "                               max_features = 1, max_samples= 1.0, n_estimators = 19, n_jobs = -1),\\\n",
    "                                 x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting rf_month index to match ls_df later\n",
    "rf_month['yyyymm'] = rf_month['yyyymm'].apply(lambda x: int(str(x)[:6]))\n",
    "rf_month.set_index(rf_month['yyyymm'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d648ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds the stock values to the predicted DataFrames\n",
    "RF_pred_df = pd.merge(RF_pred_df, merged_df['value'], left_index=True, right_index=True)\n",
    "BGDT_pred_df = pd.merge(BGDT_pred_df, merged_df['value'], left_index=True, right_index=True)\n",
    "RSDT_pred_df = pd.merge(RSDT_pred_df, merged_df['value'], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_df, ls_sub_rf_mean, ls_sub_rf_std, sharpe_ratio\n",
    "RF_ls_df, RF_ls_sub_rf_mean, RF_ls_sub_rf_std, RF_sharpe_ratio = portfolio_build(RF_pred_df, \"RF\", merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afb553",
   "metadata": {},
   "outputs": [],
   "source": [
    "BGDT_ls_df, BGDT_ls_sub_rf_mean, BGDT_ls_sub_rf_std, BGDT_sharpe_ratio = portfolio_build(BGDT_pred_df, \"BGDT\", merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSDT_ls_df, RSDT_ls_sub_rf_mean, RSDT_ls_sub_rf_std, RSDT_sharpe_ratio = portfolio_build(RSDT_pred_df, \"RSDT\", merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values from previous assignment for comparison\n",
    "assignment6_metrics = pd.read_csv(\"assignment6_metrics.csv\")\n",
    "assignment6_values = pd.read_csv(\"assignment6_values.csv\")\n",
    "\n",
    "assignment6_values.drop('Unnamed: 0', axis= 1, inplace= True)\n",
    "assignment6_values.set_index(RF_ls_df.index, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f08657",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment6_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(RF_ls_df.index, RF_ls_df['cumulative_ret'], label = 'RF')\n",
    "plt.plot(BGDT_ls_df.index, BGDT_ls_df['cumulative_ret'], label = 'BGDT')\n",
    "plt.plot(RSDT_ls_df.index, RSDT_ls_df['cumulative_ret'], label = 'RSDT')\n",
    "plt.plot(RF_ls_df.index, assignment6_values['slr_cum_ret'], label = 'SLR')\n",
    "plt.plot(RF_ls_df.index, assignment6_values['en_cum_ret'], label = 'EN')\n",
    "plt.plot(RF_ls_df.index, assignment6_values['pls_cum_ret'], label = 'PLS')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.title(\"Rolling average of portfolio values vs Time\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c9023a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The r2 scores are attained if you ran the validation_model function\n",
    "# I've just assigned them here since I'm not running the full function which takes time\n",
    "\n",
    "RF_best_r2 = 0.4023358998970291\n",
    "BGDT_best_r2 = 0.38203966204801354\n",
    "RSDT_best_r2 = 0.20295386908083823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cde15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type        Avg Ret    Std. Dev          SR         R^2\n",
      "------  -----------  ----------  ----------  ----------\n",
      "SLR      0.271556      0.28493    3.30151    0.00460928\n",
      "EN       0.266641      0.297459   3.10521    0.00483712\n",
      "PLS      0.244333      0.290277   2.91582    0.00470622\n",
      "RF      -0.00854582    0.225442  -0.131313   0.402336\n",
      "BGDT     0.00382652    0.202823   0.0653549  0.38204\n",
      "RSDT    -0.0856384     0.216177  -1.3723     0.202954\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "table = [['Type', 'Avg Ret', 'Std. Dev', 'SR', 'R^2'],\\\n",
    "         [assignment6_metrics['Type'][0], assignment6_metrics['Avg Ret'][0], assignment6_metrics['Std. Dev'][0],\\\n",
    "          assignment6_metrics['SR'][0], assignment6_metrics['R^2'][0]],\n",
    "        [assignment6_metrics['Type'][1], assignment6_metrics['Avg Ret'][1], assignment6_metrics['Std. Dev'][1],\\\n",
    "          assignment6_metrics['SR'][1], assignment6_metrics['R^2'][1]],\n",
    "        [assignment6_metrics['Type'][2], assignment6_metrics['Avg Ret'][2], assignment6_metrics['Std. Dev'][2],\\\n",
    "          assignment6_metrics['SR'][2], assignment6_metrics['R^2'][2]],\n",
    "         ['RF', RF_ls_sub_rf_mean, RF_ls_sub_rf_std, RF_sharpe_ratio, RF_best_r2],\n",
    "         ['BGDT', BGDT_ls_sub_rf_mean, BGDT_ls_sub_rf_std, BGDT_sharpe_ratio, BGDT_best_r2],\n",
    "         ['RSDT', RSDT_ls_sub_rf_mean, RSDT_ls_sub_rf_std, RSDT_sharpe_ratio, RSDT_best_r2]]\n",
    "\n",
    "print(tabulate(table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "261b8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for later use\n",
    "\n",
    "data = table[1:]\n",
    "results = pd.DataFrame(data, columns= ['Type', 'Avg Ret', 'Std. Dev', 'SR', 'R^2'])\n",
    "\n",
    "rol_val = pd.concat([assignment6_values['slr_cum_ret'],assignment6_values['en_cum_ret'], assignment6_values['pls_cum_ret'], \\\n",
    "                     RF_ls_df['cumulative_ret'], BGDT_ls_df['cumulative_ret'], RSDT_ls_df['cumulative_ret']],\\\n",
    "                     axis = 1) \n",
    "rol_val.columns = ['slr_cum_ret', 'en_cum_ret', 'pls_cum_ret', 'RF_cum_ret', 'BGDT_cum_ret', 'RSDT_cum_ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8a9cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"assignment7_metrics.csv\")\n",
    "rol_val.to_csv(\"assignment7_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c726d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
